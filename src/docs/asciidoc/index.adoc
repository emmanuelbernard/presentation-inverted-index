= Inverted indices
Emmanuel Bernard
2016-12-20
:hardbreaks:
:revnumber: {project-version}
:example-caption!:
ifndef::imagesdir[:imagesdir: images]
ifndef::sourcedir[:sourcedir: ../java]
:deckjs_transition: fade
:revealjs_slideNumber: 'c/t'
:navigation:
:menu:
:status:
:stem:

== What are we here for

Discuss inverted index technology and fundamentals

=== Emmanuel Bernard

++++
<style>
.asciinema-terminal.font-medium {
  font-size: 16px;
}
</style>
++++

Consulting Software Engineer, Red Hat
Platform Architect
Open Source coder:

* Hibernate {ORM,OGM,Search,Validator}
* Debezium, Infinispan, Ceylon, ...

Podcasts: https://lescastcodeurs.com:[Les Cast Codeurs]

https://twitter.com/emmanuelbernard[@emmanuelbernard]
https://emmanuelbernard.com

=== Agenda

TODO: TBD

== Why do we need inverted index

=== Where is it used

[.left]
--
Classical:

* Google, DuckDuckGo
* Mobile phone search
* IDE  auto-completion
--

[.right]
--
Less classical

* geolocation
* suggestion
* faceting
* more like this / classification
* machine learning
--

=== Let's try on RDBMSes

[source,SQL]
----
SELECT * FROM Speakers s WHERE s.bio = 'Open Source'
----

B-Tree index

[#fundamental]
== A zoom on B-Trees

Self-balancing tree data stucture
Search, insert and delete in `O(log n)`
Good when access time >> process time

Replace numbers in the example with letters for text.

image::b-tree/b-tree-base.png[]

[#fundamental]
=== Splitting leaf nodes

[.left]
--
image::b-tree/b-tree-base.png[]
--

[.right]
--
image::b-tree/b-tree-1.png[]
--

[#fundamental]
=== Simple addition

[.left]
--
image::b-tree/b-tree-1.png[]
--

[.right]
--
image::b-tree/b-tree-2.png[]
--

[#fundamental]
=== Splitting nodes

[.left]
--
image::b-tree/b-tree-2.png[]
--

[.right]
--
image::b-tree/b-tree-3.png[]
--

[#fundamental]
=== Filling up a leaf node

[.left]
--
image::b-tree/b-tree-3.png[]
--

[.right]
--
image::b-tree/b-tree-4.png[]
--

[#fundamental]
=== Splitting nodes and filling up the root

[.left]
--
image::b-tree/b-tree-4.png[]
--

[.right]
--
image::b-tree/b-tree-5.png[]
--

[#fundamental]
=== Filling up leaves

[.left]
--
image::b-tree/b-tree-5.png[]
--

[.right]
--
image::b-tree/b-tree-6.png[]
--

[#fundamental]
=== Adding one level

[.left]
--
image::b-tree/b-tree-6.png[]
--

[.right]
--
image::b-tree/b-tree-7.png[]
--

[#fundamental]
=== B+-tree

Only keys in the non leaf nodes
Leaf nodes linked with one another for efficient ascending reading
Data can be just pointer to the real data

== Back to our RDBMS vs inverted indices

=== With like

[source,SQL]
----
SELECT * FROM Speakers s WHERE s.bio LIKE 'Open Source%'
----

With like we can have more text after
Still using indices

=== With like in the middle of the column

[source,SQL]
----
SELECT * FROM Speakers s WHERE s.bio LIKE '%Open Source%'
----

Find word anywhere in the text

Table or index scan :(

=== What about uppercase, typos etc

[source,SQL]
----
SELECT * FROM Speakers s WHERE
    s.bio LIKE '%open source%'
    OR s.bio LIKE '%Open Source%'
    OR s.bio LIKE '%opan surce%'
----

Can't anticipate the casing
Can't anticipate all typos

=== What about word ordering and priority

[source,SQL]
----
SELECT * FROM/Speakers s WHERE
    s.bio LIKE '%source open%'
    OR s.bio LIKE '%source%'
    OR s.bio LIKE '%open%'
    ORDER BY best??
----

Words could be in any order
I want the most interesting result first

== Indexing

=== Inverted index to the rescue

Let's not index column values but words
Let's not query values but words

=== At indexing time

[.left.small]
--
doc1: I am your father Luke
doc2: Yes he is your father
doc3: I am gonna make him an offer he can not refuse.
doc4: I love the smell of napalm in the morning.
doc5: One morning I shot an elephant in my pajamas. How he got in my pajamas, I do not know.
--

[.right.small]
--
|===
|word|documents

|am|1,3
|an|3,5
|can|3
|do|5
|elephant|5
|father|1,2
|gonna|3
|got|5
|he|2,3,5
|him|3
|how|5
|i|1,3,4,5
|in|4,5
|is|2
|know|5
|love|4
|luke|1
|make|3
|morning|4,5
|my|5
|not|3,5
|napalm|4
|of|4
|offer|3
|one|5
|pajamas|5
|refuse|3
|shot|5
|smell|4
|the|4
|yes|2
|your|1,2
|===
--

=== At query time

`query: father napalm`
Apply the same word splitting logic
Matching documents: 1, 2 and 4

|===
|word|documents

|father|1,2
|napalm|4
|===



== Indexing details

=== Transforming sentences into words

1. pre-tokenization
2. tokenization
3. filter

Apply the same logic to both document and query content
Each token is the entry in the inverted index pointing to documents

=== Pre-tokenization

Remove unnecessary characters
e.g. remove HTML tags

[source]
----
<p>This is <string>awesome</strong>.</p>
This is awesome.
----

=== Tokenization

Split sentence into words called _tokens_
Split at spaces, dots and other punctuations (with exceptions)

`aujourd'hui`, `A.B.C.`, and many other rules

One tokenizer per language, but many languages are similar

[#aside]
=== Continuous scripting

Didyouknowwritingtextsinwordsseparatedbyspaceisnotthatold
itstartedinthemiddleage
Itwasnotaproblemaspeoplewerereadingoutloudwrittentext
Infactsplittingwordswasaninventionnecessary
becausemonksshouldremainsilentandlatinwasnolongertheirnativetongue

=== Filtering: where the magic happens

Operate on the stream of tokens
Change, remove or even add tokens

lowercase, stopwords

[source]
--
Sentence: This is AWESOME Peter!
Tokens: |This|is|AWERSOME|Peter|
stopwords: |AWESOME|Peter|
lowercase: |awesome|peter|
--

=== Solving various problems with filters

=== Synonyms

When the text mentions a "car" but the research is about "automobile" or "vehicle"
We need a synonym dictionary.

=== Synonym solution

1. Put all synonyms in the index for each word
2. Use a reference synonym ("automobile" for "car", "compact", "auto", "S.U.V."...)
3. index normally, use synonyms when building the query

=== Words from the same family

"education", "educates", "educated", ...
That would make for lots of synonyms...
Let's use a stemming algorithm

=== An algorithm to copy language logic (and exceptions)

[.left]
--
Porter stemming algorithm
Snowball grammar
http://snowballstem.org/algorithms/french/stemmer.html[French algorithm explained]

Index/query the stem when the word in found
--

[.right]
--
|===
|word|stem

|main|main
|mains|main
|maintenaient|mainten
|maintenait|mainten
|maintenant|mainten
|maintenir|mainten
|maintenue|mainten
|maintien|maintien
|==
--

=== Finding words with typos

People make mistakes
In the text or in the query

They make _thaipo_ and other _mystakes_

=== Phonetic algorithm

Same logic as stemming, convert word into phonetic approximation
Soundex, RefinedSoundex, Metaphone, DoubleMetaphone

[NOTE.speaker]
--
* Soundex most well known and oldest
* RefinedSoundex more focused on spell checking
* Metaphone: variable length phonetic approximation
* Double Metaphone: handles more irregularities from English, German, Greek, French, Chinese

Phonetic algorithms relatively costly
--

=== n-gram

Split a word into a sliding window of n characters
Index each n-gram

low n means more false positive
high n means less forgiving

[source]
--
// building a 3 gram
mystake: mys yst sta tak ake
mistake: mis ist sta tak ake
--

=== Fuzzy search

Based on Damerau-Levenshtein distance

* insert, update, delete and transposition

Pure query time operation

=== Fuzzy search in practice

Compute distance between word and all words in index

Compute a distance state machine for word
Use it to check specific terms in the index

[.left.small]
--
n^e^: n consummed chars, e errors
horizontal: unmodified chars
* vertical: addition
* diagonal: substitution
ε diagonal: deletion
--

[.right]
--
image::fuzzy/levenstein-nfa-food.png[]
--

[NOTE.speaker]
--
Read https://julesjacobs.github.io/2015/06/17/disqus-levenshtein-simple-and-fast.html and http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata
The image is a Non deterministic Finite Automaton
--

=== You can index the same data in different ways

Apply different indexing approach for same data

== Querying time

It's _term_ query all the way down!
All queries (synonyms, phonetic, n-gram, fuzzy) are a (set of) term queries

=== Possible queries

TODO: possible queries?
Term, wildcard, prefix, fuzzy, phrase, range, boolean, all, spatial, more like this, spell checking

== Scoring

We want the most relevant results first
This is relative
Several approaches, none perfect

=== Main levers for a scoring formulae

Term frequency::
How often does the term appear in this document?
More is better

Inverse document frequency::
How often does the term appear in all documents in the collection?
Common words are less important

Field-length norm::
How long is the field?
Long documents would be favored otherwise

Coordination factor::
If document contains multiple terms, it's a better fit.

[%step]
=== TF/IDF Full formulae

[stem.small]
++++
"score"(q,d) =
    "queryNorm"(q)
    * "coord"(q,d)
    * sum_(t in q) (
        tf(t in d)
        * idf(t)^2
        * "t.boost"
        * "norm"(t,d)
    )
++++

[stem.small]
++++
"queryNorm"(q) = 1/sqrt(sum_(t in q) (idf(t)^2))
++++

[stem.small]
++++
"coord"(q,d) = ("matchingTerm"(q))/("nbrOfTerms"(q))
++++

[stem.small]
++++
tf(t in d) = sqrt(nbrOfTermAppearance(t in d))
++++

[stem.small]
++++
idf(t) = 1 + log ( "numDocs" / ("numDocs"(t in d) + 1)) 
++++

[stem.small]
++++
"norm"(d) = 1/sqrt( "nbrOfTerms"(t in d) )
++++

=== Other scoring

Boosting fields
Okapi BM25
Your custom scoring function (or a tweak of)

== Inverted index physical representation

A Lucene example

=== File structure

[NOTE.speaker]
--
B-Tree, not fast enough
--

=== Log-Structured Merge

=== Uninverted index

== Thank you!

* Slides and code : https://github.com/melix/virtualjug-fast-builds
* Gradle documentation : http://gradle.org/documentation/
* Follow me: http://twitter.com/CedricChampeau[@CedricChampeau]

Learn more at https://gradle.org[www.gradle.org]


