= Inverted index
Emmanuel Bernard
2016-12-20
:hardbreaks:
:revnumber: {project-version}
:example-caption!:
ifndef::imagesdir[:imagesdir: images]
ifndef::sourcedir[:sourcedir: ../java]
:deckjs_transition: fade
:revealjs_slidenumber: false
:navigation:
:menu:
:status:
:stem:

== What are we here for

Discuss inverted index technology and fundamentals

=== Emmanuel Bernard

++++
<style>
.asciinema-terminal.font-medium {
  font-size: 16px;
}
</style>
++++

Consulting Software Engineer, Red Hat
Platform Architect
Open Source coder:

* Hibernate {ORM,OGM,Search,Validator}
* Debezium, Infinispan, Ceylon, ...

Podcasts: https://lescastcodeurs.com:[Les Cast Codeurs]

https://twitter.com/emmanuelbernard[@emmanuelbernard]
https://emmanuelbernard.com

=== Agenda

TODO: TBD

== Why do we need inverted index

=== Where is it used

[.left]
--
Classical:

* Google, DuckDuckGo
* Mobile phone search
* IDE  auto-completion
--

[.right]
--
Less classical

* geolocation
* suggestion
* faceting
* more like this / classification
* machine learning
--

=== Let's try on RDBMSes

[source,SQL]
----
SELECT * FROM Speakers s WHERE s.bio = 'Open Source'
----

B-Tree index

[.fundamental]
== A zoom on B-Trees

Self-balancing tree data stucture
Search, insert and delete in `O(log n)`
Good when access time >> process time

Replace numbers in the example with letters for text.

image::b-tree/b-tree-base.png[]

[.fundamental]
=== Splitting leaf nodes

[.left]
--
image::b-tree/b-tree-base.png[]
--

[.right]
--
image::b-tree/b-tree-1.png[]
--

[.fundamental]
=== Simple addition

[.left]
--
image::b-tree/b-tree-1.png[]
--

[.right]
--
image::b-tree/b-tree-2.png[]
--

[.fundamental]
=== Splitting nodes

[.left]
--
image::b-tree/b-tree-2.png[]
--

[.right]
--
image::b-tree/b-tree-3.png[]
--

[.fundamental]
=== Filling up a leaf node

[.left]
--
image::b-tree/b-tree-3.png[]
--

[.right]
--
image::b-tree/b-tree-4.png[]
--

[.fundamental]
=== Splitting nodes and filling up the root

[.left]
--
image::b-tree/b-tree-4.png[]
--

[.right]
--
image::b-tree/b-tree-5.png[]
--

[.fundamental]
=== Filling up leaves

[.left]
--
image::b-tree/b-tree-5.png[]
--

[.right]
--
image::b-tree/b-tree-6.png[]
--

[.fundamental]
=== Adding one level

[.left]
--
image::b-tree/b-tree-6.png[]
--

[.right]
--
image::b-tree/b-tree-7.png[]
--

[.fundamental]
=== B+-tree

Only keys in the non leaf nodes
Leaf nodes linked with one another for efficient ascending reading
Data can be just pointer to the real data

== Back to our RDBMS vs inverted indices

=== With like

[source,SQL]
----
SELECT * FROM Speakers s WHERE s.bio LIKE 'Open Source%'
----

With like we can have more text after
Still using indices

=== With like in the middle of the column

[source,SQL]
----
SELECT * FROM Speakers s WHERE s.bio LIKE '%Open Source%'
----

Find word anywhere in the text

Table or index scan :(

=== What about uppercase, typos etc

[source,SQL]
----
SELECT * FROM Speakers s WHERE
    s.bio LIKE '%open source%'
    OR s.bio LIKE '%Open Source%'
    OR s.bio LIKE '%opan surce%'
----

Can't anticipate the casing
Can't anticipate all typos

=== What about word ordering and priority

[source,SQL]
----
SELECT * FROM/Speakers s WHERE
    s.bio LIKE '%source open%'
    OR s.bio LIKE '%source%'
    OR s.bio LIKE '%open%'
    ORDER BY best??
----

Words could be in any order
I want the most interesting result first

== Indexing

=== Inverted index to the rescue

Let's not index column values but words
Let's not query values but words

=== At indexing time

[.left.small]
--
doc1: I am your father Luke
doc2: Yes he is your father
doc3: I am gonna make him an offer he can not refuse.
doc4: I love the smell of napalm in the morning.
doc5: One morning I shot an elephant in my pajamas. How he got in my pajamas, I do not know.
--

[.right.small]
--
|===
|word|documents

|am|1,3
|an|3,5
|can|3
|do|5
|elephant|5
|father|1,2
|gonna|3
|got|5
|he|2,3,5
|him|3
|how|5
|i|1,3,4,5
|in|4,5
|is|2
|know|5
|love|4
|luke|1
|make|3
|morning|4,5
|my|5
|not|3,5
|napalm|4
|of|4
|offer|3
|one|5
|pajamas|5
|refuse|3
|shot|5
|smell|4
|the|4
|yes|2
|your|1,2
|===
--

=== At query time

`query: father napalm`
Apply the same word splitting logic
Matching documents: 1, 2 and 4

|===
|word|documents

|father|1,2
|napalm|4
|===



== Indexing details

=== Transforming sentences into words

1. pre-tokenization
2. tokenization
3. filter

Apply the same logic to both document and query content
Each token is the entry in the inverted index pointing to documents

=== Pre-tokenization

Remove unnecessary characters
e.g. remove HTML tags

[source]
----
<p>This is <strong>awesome</strong>.</p>
This is awesome.
----

=== Tokenization

Split sentence into words called _tokens_
Split at spaces, dots and other punctuations (with exceptions)

`aujourd'hui`, `A.B.C.`, and many other rules

One tokenizer per language, but many languages are similar

[.aside]
=== Continuous scripting

Didyouknowwritingtextsinwordsseparatedbyspaceisnotthatold
itstartedinthemiddleage
Itwasnotaproblemaspeoplewerereadingoutloudwrittentext
Infactsplittingwordswasaninventionnecessary
becausemonksshouldremainsilentandlatinwasnolongertheirnativetongue

=== Filtering: where the magic happens

Operate on the stream of tokens
Change, remove or even add tokens

lowercase, stopwords

[source]
--
Sentence: This is AWESOME Peter!
Tokens: |This|is|AWESOME|Peter|
stopwords: |AWESOME|Peter|
lowercase: |awesome|peter|
--

=== Solving various problems with filters

=== Synonyms

When the text mentions a "car" but the research is about "automobile" or "vehicle"
We need a synonym dictionary.

=== Synonym solution

1. Put all synonyms in the index for each word
2. Use a reference synonym ("automobile" for "car", "compact", "auto", "S.U.V."...)
3. index normally, use synonyms when building the query

=== Words from the same family

"education", "educates", "educated", ...
That would make for lots of synonyms...
Let's use a stemming algorithm

=== An algorithm to copy language logic (and exceptions)

[.left]
--
Porter stemming algorithm
Snowball grammar
http://snowballstem.org/algorithms/french/stemmer.html[French algorithm explained]

Index/query the stem when the word is found
--

[.right]
--
|===
|word|stem

|main|main
|mains|main
|maintenaient|mainten
|maintenait|mainten
|maintenant|mainten
|maintenir|mainten
|maintenue|mainten
|maintien|maintien
|==
--

=== Finding words with typos

People make mistakes
In the text or in the query

They make _thaipo_ and other _mystakes_

=== Phonetic algorithm

Same logic as stemming, convert word into phonetic approximation
Soundex, RefinedSoundex, Metaphone, DoubleMetaphone

[NOTE.speaker]
--
* Soundex most well known and oldest
* RefinedSoundex more focused on spell checking
* Metaphone: variable length phonetic approximation
* Double Metaphone: handles more irregularities from English, German, Greek, French, Chinese

Phonetic algorithms relatively costly
--

=== n-gram

Split a word into a sliding window of n characters
Index each n-gram

low n means more false positives
high n means less forgiving

[source]
--
// building a 3 gram
mystake: mys yst sta tak ake
mistake: mis ist sta tak ake
--

=== Fuzzy search

Based on Damerau-Levenshtein distance

* insert, update, delete and transposition

Pure query time operation

=== Fuzzy search in practice

Compute distance between word and all words in index

Compute a distance state machine for word
Use it to check specific terms in the index

[.left.small]
--
n^e^: n consumed chars, e errors
horizontal: unmodified chars
* vertical: addition
* diagonal: substitution
ε diagonal: deletion
--

[.right]
--
image::fuzzy/levenstein-nfa-food.png[]
--

[NOTE.speaker]
--
Read https://julesjacobs.github.io/2015/06/17/disqus-levenshtein-simple-and-fast.html and http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata
The image is a Non deterministic Finite Automaton
--

=== You can index the same data in different ways

Apply different indexing approach for same data

== Querying time

It's _term_ query all the way down!
All queries (synonyms, phonetic, n-gram, fuzzy) are a (set of) term queries

=== Possible queries

TODO: possible queries?
Term, wildcard, prefix, fuzzy, phrase, range, boolean, all, spatial, more like this, spell checking

== Scoring

We want the most relevant results first
This is relative
Several approaches, none perfect

=== Main levers for a scoring formulae

Term frequency::
How often does the term appear in this document?
More is better

Inverse document frequency::
How often does the term appear in all documents in the collection?
Common words are less important

Field-length norm::
How long is the field?
Long documents would be favored otherwise

Coordination factor::
If document contains multiple terms, it's a better fit.

[%step]
=== TF/IDF Full formulae

[stem.small]
++++
"score"(q,d) =
    "queryNorm"(q)
    * "coord"(q,d)
    * sum_(t in q) (
        tf(t in d)
        * idf(t)^2
        * "t.boost"
        * "norm"(t,d)
    )
++++

[stem.small]
++++
"queryNorm"(q) = 1/sqrt(sum_(t in q) (idf(t)^2))
++++

[stem.small]
++++
"coord"(q,d) = ("matchingTerm"(q))/("nbrOfTerms"(q))
++++

[stem.small]
++++
tf(t in d) = sqrt(nbrOfTermAppearance(t in d))
++++

[stem.small]
++++
idf(t) = 1 + log ( "numDocs" / ("numDocs"(t in d) + 1)) 
++++

[stem.small]
++++
"norm"(d) = 1/sqrt( "nbrOfTerms"(t in d) )
++++

=== Other scoring

Boosting fields
Okapi BM25
Your custom scoring function (or a tweak of)

== Inverted index physical representation

A Lucene example

[.fundamental]
=== B-tree's problems

When you need write throughput
B-tree require lots of update in place
Sequential reads are much faster than random reads

* in memory
* on disk

[.fundamental]
=== Append logs

Append operations in a file
Reading requires reading all the log

[.fundamental]
=== Log-Structured Merge

Per batch of writes, create a file storing the sorted key/value pairs
On read, check for the key on each file
Regularly merge files together (e.g. make bigger files)

image::lsm/lsm-base.png[Log-Structured Merge Tree]

[.fundamental]
=== LSM characteristics

Immutable (lock-free) and file cache friendly
Fast on write, decent on read
Sequential read/write friendly
Read time decays with number of files => merge

[.fundamental]
=== Lots of ways to improve them

Bloom filter
Page index in memory
Levelled compaction

[.fundamental]
=== Levelled LSM tree

image::lsm/lsm-levelled-compaction.png[Log-Structured Merge Tree]

[.fundamental]
=== Levelled compaction

Limit the number of files to read
Compact to the higher levels
Each file per level has non overlapping key ranges
One file per level to be consulted

=== Lucene's case

LSM
Everything is computed upfront
Each _segment_ is a mini index
Denormalize differently depending on access pattern

=== A segment (simplified)

* term index (like a ToC for the dictionary)
* term dictionary (points to posting list offset)
* posting list (list of matching document id per term)
* stored field index (sparse doc id + offset)
* stored field data (list of field values per document id)
* deleted documents

=== Term index

Term index provides offset to the dictionary
Based on _finite state transducers_
Gives one ordinal per prefix

We know where to look in the term dictionary

[.left]
--
image::file-structure/FSTExample.png[]
--

[.right.small]
--
FST for mop, moth, pop, star, stop and top

[source]
----
mop=0
moth=1
pop=2
star=3
stop=4
top=5
----
--


[NOTE.speaker]
--
Thanks to immutable, can be built at merge time
Thanks to immutable, replace term with its ordinal value and index in a virtual array
Terms are ordered alphabetically and given an ordinal => alter comparison by ordinal comparison
--

=== Term dictionary

From a given offset (& prefix)
Sorted list of suffixes
For each, frequency and offset to posting list

[source]
----
[prefix=top]
_null_, freq=27, offset=234
ography, freq=1, offset=298
ology, freq=6, offset=306
onyms, freq=1, offset=323
----

=== Posting list

List of document ids
Encoded as delta of ids (good for variable int encoding)

[source]
----
4,6,9,30,33,39,45 => 4,2,3,23,3,6,6
----

http://www2008.org/papers/pdf/p387-zhangA.pdf[PForDelta] encoding
Bigger in size but less CPU branch miss prediction

[NOTE.speaker]
--
PForDelta
By batch of 128 integers, find the smallest number of bits for the biggest int
And use this as fixed encoding.
Note that it has a notion of exception for ints bigger than b bits to improve the logic
--

=== Stored fields

Stored field index in memory doc id + offset for every 16k of data
Stored value stored as bocks of 16k and compressed

image::file-structure/stored-fields.png[]

=== Deleted documents

You said segments are immutable
What about deleted documents?

Deleted document file

* 1 bit per doc
* sparse list of cleared docs

=== Why oh why such a mess?

2 disk seeks per field search (binary search)
1 disk seek per doc for stored fields

But things likely fit in file system cache

Warning: this is a simplified view :)

== Subjects not covered

=== Uninverted index

Columnar storage
Called doc values
Used for aggregation or sorting or faceting

=== Faceting

=== Position

=== Geospatial queries

=== Term vector

=== Shingles

=== And many more things


== Thank you!

* Slides https://emmanuelbernard.com/presentations/inverted-index/
* Code https://github.com/emmanuelbernard/presentation-inverted-index/
* Blog https://emmanuelbernard.com[emmanuelbernard.com]
* Follow me: http://twitter.com/emmanuelbernard[@emmanuelbernard]

=== References

TODO: fill up all references

=== TODO

Put some fun breaks every now and then
